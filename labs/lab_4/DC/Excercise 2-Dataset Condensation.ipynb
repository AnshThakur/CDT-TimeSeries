{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ§  Dataset Condensation via Distribution Matching (PyTorch Implementation)\n",
    "\n",
    "### ðŸ“˜ Primer\n",
    "\n",
    "This notebook implements **Dataset Condensation using Distribution Matching (DM)** â€” a data-efficient learning approach that synthesizes a *compact yet representative* set of samples capable of training models nearly as well as the full dataset.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ§© What is Dataset Condensation?\n",
    "\n",
    "Dataset Condensation aims to **compress a large dataset into a much smaller synthetic set** that preserves the original dataâ€™s learning signal.  \n",
    "Instead of storing millions of real examples, we learn a small synthetic dataset `x_syn, y_syn` such that models trained on it achieve similar generalization.\n",
    "\n",
    "In this implementation, we use **Distribution Matching (DM)** â€” a technique that aligns feature distributions between real and synthetic data in the output space of a neural network.  \n",
    "At each iteration, synthetic data are updated to minimize the discrepancy between the mean activations of real and synthetic examples.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸš€ Workflow Overview\n",
    "\n",
    "1. **Setup & Reproducibility**\n",
    "   - Import required libraries.\n",
    "   - Define deterministic seeds for Python, NumPy, and PyTorch.\n",
    "   - Set key experiment hyperparameters (`ipc`, `eval_net_type`, `optim`, etc.).\n",
    "\n",
    "2. **Data Loading**\n",
    "   - Load and preprocess the time-series dataset (train/val/test splits).\n",
    "   - Infer model input dimensions from a single training batch.\n",
    "\n",
    "3. **Synthetic Data Initialization**\n",
    "   - Initialize `x_syn` and `y_syn` either from random noise (`init='rand'`) or sampled real examples (`init='real'`).\n",
    "   - Attach gradients to `x_syn` so it can be optimized directly.\n",
    "\n",
    "4. **Baseline Evaluation**\n",
    "   - Train a baseline model (LSTM/RNN) on the initial synthetic data.\n",
    "   - Compute validation and test performance (AUC/APR) before condensation.\n",
    "\n",
    "5. **Distribution Matching Loop**\n",
    "   - For each iteration:\n",
    "     - Randomly sample real data from each class.\n",
    "     - Pass real and synthetic data through a frozen random network.\n",
    "     - Compute **DM loss** = squared distance between mean feature activations.\n",
    "     - Backpropagate through synthetic data and update `x_syn` via SGD.\n",
    "   - Periodically evaluate on validation data and save the best synthetic set.\n",
    "\n",
    "6. **Final Evaluation**\n",
    "   - Load the best condensed dataset (`x_syn`, `y_syn`).\n",
    "   - Train a fresh model from scratch on this condensed dataset.\n",
    "   - Evaluate on validation and test sets to measure performance retention.\n",
    "\n",
    "---\n",
    "\n",
    "### âš™ï¸ Key Parameters\n",
    "\n",
    "| Parameter | Description | Example |\n",
    "|------------|-------------|----------|\n",
    "| `ipc` | Instances per class to synthesize | `100` |\n",
    "| `init` | Initialization mode (`rand` or `real`) | `'rand'` |\n",
    "| `optim` | Optimizer for condensation (`sgd` / `adam`) | `'sgd'` |\n",
    "| `eval_it` | Frequency (in iterations) for validation evaluation | `250` |\n",
    "| `Iteration` | Total number of condensation iterations | `5000` |\n",
    "| `eval_net_type` | Evaluation model architecture | `'lstm'` or `'rnn'` |\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ§ª Objective\n",
    "\n",
    "By the end of training, youâ€™ll obtain a **synthetic dataset** that:\n",
    "- Drastically reduces data size,\n",
    "- Retains predictive power,\n",
    "- Can be reused to train new models efficiently.\n",
    "\n",
    "This forms the basis for scalable data-efficient learning and privacy-preserving model training â€” useful in resource-limited or federated settings.\n",
    "\n",
    "---\n",
    "\n",
    "> **References**\n",
    "> - Zhao & Bilen (2021), *Dataset Condensation with Gradient Matching*  \n",
    "> - Zhao et al. (2023), *Dataset Condensation via Distribution Matching*\n",
    "> - PyTorch-based open-source reimplementations\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸŽ¯ Exercises â€” Explore and Compare\n",
    "\n",
    "Use these guided experiments to deepen your understanding of **Distribution Matching for Dataset Condensation**.\n",
    "\n",
    "1. **Vary the number of instances per class (`ipc`)**\n",
    "   - Change `ipc` in the setup cell (e.g. `ipc = 500`, `200`, `50`, `10`).\n",
    "   - Re-run the experiment and note:\n",
    "     - How does validation/test **AUC** change as `ipc` decreases?\n",
    "     - How does training time scale with smaller synthetic datasets?\n",
    "\n",
    "2. **Change the initialization strategy**\n",
    "   - Switch between  \n",
    "     - `init = 'rand'` â†’ purely random noise,  \n",
    "     - `init = 'real'` â†’ sampled from true data.\n",
    "   - Observe how the **convergence speed** and **final synthetic quality** differ.\n",
    "\n",
    "3. **Compare models trained on real vs. synthetic data**\n",
    "   - From **Exercise 1**, you already trained a baseline model on the **real dataset**.\n",
    "   - Now, compare its test performance with the model trained here on **synthetic data**.\n",
    "   - Discuss:\n",
    "     - How close does the synthetic dataset come to the real datasetâ€™s performance?\n",
    "     - Which metrics (AUROC, AUPRC) show the largest gap?\n",
    "\n",
    "4. **Change evaluation architecture**\n",
    "   - Try `eval_net_type = 'rnn'` vs. `'lstm'` (or even a CNN/MLP if applicable).\n",
    "   - Does a more expressive model help capture patterns from condensed data?\n",
    "\n",
    "5. **Inspect learned synthetic samples**\n",
    "   - Visualize `x_syn` for each class (plot feature distributions or sample sequences).\n",
    "   - Do the synthetic examples resemble the original dataâ€™s temporal structure?\n",
    "\n",
    "---\n",
    "\n",
    "ðŸ§­ **Goal:**  \n",
    "By the end of these exercises, you should understand:\n",
    "- How data condensation quality depends on `ipc` and initialization.  \n",
    "- The trade-off between dataset size and generalization.  \n",
    "- How well condensed data generalize across different model architectures.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### ðŸ”§ Setup: Reproducibility and Imports\n",
    "# \n",
    "# This cell:\n",
    "# - Imports all required libraries.\n",
    "# - Defines a `set_seed()` utility to make runs deterministic.\n",
    "# - Ensures consistent results across NumPy, Python, and PyTorch.\n",
    "\n",
    "# %%\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from models import get_net\n",
    "# project-specific helpers\n",
    "from utils_1 import *\n",
    "from loaders import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # Ignore all warnings\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def set_seed(seed: int = 42) -> None:\n",
    "    \"\"\"\n",
    "    Ensure full reproducibility across Python, NumPy, and PyTorch.\n",
    "    This helps compare condensation runs fairly.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    # Make CuDNN (PyTorch backend) deterministic\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "# Set random seed once for the whole notebook\n",
    "SEED = 42\n",
    "set_seed(SEED)\n",
    "print(f\"âœ… Random seed set to {SEED}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# `ipc` = *instances per class* to synthesize.  \n",
    "# Adjust these to control how much synthetic data is generated.\n",
    "\n",
    "# %%\n",
    "ipc = 100             # instances per class to synthesize (e.g. 500, 200, 100, 50, 10)\n",
    "init = 'rand'        # initialization: 'real' (sampled real data) or 'rand' (random noise)\n",
    "optim = 'sgd'        # optimizer for condensation: 'sgd' or 'adam'\n",
    "eval_net_type = 'lstm'  # model type for evaluation: 'rnn' or 'lstm' (we will train this model on synthesised data for evaluation)\n",
    "\n",
    "print(f\"ipc={ipc}, init='{init}', optim='{optim}', eval_net_type='{eval_net_type}'\")\n",
    "device = get_device()\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    lr_x = 100\n",
    "    mom_x = 0.99\n",
    "    Iteration = 5000\n",
    "    batch_real = 256\n",
    "    eval_it = 250\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train_batch = 256\n",
    "\n",
    "# -------------------------\n",
    "# Load data (adjust `path` to where your pickles are)\n",
    "# -------------------------\n",
    "data_path = \"../DATA/\"   # <-- change to your data folder\n",
    "train_loader, val_loader, test_loader = get_loaders_time_series(\n",
    "    path=data_path,\n",
    "    train_batch=train_batch,\n",
    "    val_batch=256,\n",
    "    test_batch=256,\n",
    "    sampler=True,\n",
    "    pre_process=\"std\",\n",
    "    ds_half=0,\n",
    ")\n",
    "\n",
    "# Inspect one batch shape to infer model input dims\n",
    "batch_x, batch_y = next(iter(train_loader))\n",
    "print(\"One batch x shape:\", batch_x.shape, \"y shape:\", batch_y.shape)\n",
    "# typical shape: (batch, seq_len, n_features)\n",
    "\n",
    "seq_len = batch_x.shape[1]\n",
    "n_features = batch_x.shape[2]\n",
    "print(f\"seq_len={seq_len}, n_features={n_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize synthetic data\n",
    "if init == 'rand':\n",
    "    print('Initializing condensed data and labels from random noise data')\n",
    "    x_syn, y_syn, _ = initialize_synthetic_data(train_loader, ipc, device, rand_real=True)\n",
    "\n",
    "else:\n",
    "    print('Initializing condensed data from random real data and binary labels')\n",
    "    x_syn, y_syn, _ = initialize_synthetic_data(train_loader, ipc, device, real=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ### ðŸ§© Baseline performance\n",
    "# Train and evaluate a baseline model on synthetic data (x_syn, y_syn)\n",
    "# using the chosen network type and optimizer.\n",
    "\n",
    "# %%\n",
    "# Initialize baseline network\n",
    "baseline_net = get_net(net_type=eval_net_type, input_dim=n_features, device=device).to(device)\n",
    "\n",
    "# Binary classification loss (expects logits as model outputs)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Train and evaluate on validation set\n",
    "# Returns: validation AUC, (val_loss ignored here), validation APR, and trained model\n",
    "val_auc, _, val_apr, baseline_net = train_and_evaluate(\n",
    "    baseline_net,\n",
    "    x_syn, y_syn,\n",
    "    val_loader,\n",
    "    device,\n",
    "    criterion,\n",
    "    optim=optim,      # optimizer type: 'sgd' or 'adam'\n",
    "    lr=0.0001,        # learning rate\n",
    "    epochs=25,        # number of training epochs\n",
    "    mom=0.9           # momentum (for SGD)\n",
    ")\n",
    "\n",
    "print(f\"Val AUC/AUPRC : {val_auc:.4f}/{val_apr:.4f}\")\n",
    "\n",
    "# Evaluate trained model on test set\n",
    "test_auc, _, test_apr = prediction_binary(baseline_net, test_loader, criterion, device)\n",
    "print(f\"Test AUC/AUPRC: {test_auc:.4f}/{test_apr:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure x_syn, y_syn are on the correct device and have appropriate grad requirements\n",
    "x_syn = x_syn.to(device)\n",
    "y_syn = y_syn.to(device)\n",
    "x_syn.requires_grad = True\n",
    "\n",
    "optimizer_x = torch.optim.SGD([x_syn], lr=args.lr_x, momentum=args.mom_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the original train data getter: get random n data from class c\n",
    "num_classes = 2\n",
    "tr_data, tr_lb = get_data_array(train_loader)\n",
    "get_data = build_data_getter(tr_data, tr_lb, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved, commented version of your training / condensation loop\n",
    "\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# --- Initialization / bookkeeping ---\n",
    "best = -float(\"inf\")          # best validation AUC seen so far (use -inf to allow any first result)\n",
    "loss_sum = 0.0                # running sum of DM loss across iterations (for printing / logging)\n",
    "iters_since_eval = 0          # counts iterations since last evaluation (helps averaging)\n",
    "best_x_syn = None\n",
    "best_y_syn = None\n",
    "\n",
    "# Learning loop\n",
    "for it in range(args.Iteration):\n",
    "    iters_since_eval += 1\n",
    "\n",
    "    # ---- Periodic evaluation (run every args.eval_it iterations) ----\n",
    "    if (it + 1) % args.eval_it == 0:\n",
    "\n",
    "        # Create a fresh evaluation network (same architecture/type you use for eval).\n",
    "        # Move it to the correct device and ensure it's in evaluation mode inside train_and_evaluate.\n",
    "        eval_net = get_net(net_type=eval_net_type,\n",
    "                           input_dim=n_features,\n",
    "                           device=device).to(device)\n",
    "\n",
    "        # Train/evaluate on validation set (train_and_evaluate should handle .train/.eval internally).\n",
    "        # We pass clones of synthetic tensors to avoid accidental in-place changes.\n",
    "        val_auc, _, val_apr, _ = train_and_evaluate(\n",
    "            eval_net,\n",
    "            x_syn.clone(),\n",
    "            y_syn.clone(),\n",
    "            val_loader,\n",
    "            device,\n",
    "            criterion,\n",
    "            lr=0.001,\n",
    "            epochs=50,\n",
    "            optim=optim,\n",
    "            mom=0.9\n",
    "        )\n",
    "\n",
    "        # Average DM loss across the iterations since last eval for logging.\n",
    "        avg_dm_loss = loss_sum / max(1, iters_since_eval)\n",
    "\n",
    "        print(\n",
    "            f\"Itr {it + 1}, \"\n",
    "            f\"Val AUC: {val_auc:.4f}, \"\n",
    "            f\"Val AUPRC: {val_apr:.4f}, \"\n",
    "            f\"DM Loss (avg over last {iters_since_eval} iters): {avg_dm_loss:.5f}\"\n",
    "        )\n",
    "\n",
    "        # Reset the running loss counters for the next evaluation window.\n",
    "        loss_sum = 0.0\n",
    "        iters_since_eval = 0\n",
    "\n",
    "        # If validation improved, save the current synthetic dataset (deep-copied to CPU).\n",
    "        if val_auc > best:\n",
    "            best = val_auc\n",
    "            best_x_syn = x_syn.clone().detach().cpu()\n",
    "            best_y_syn = y_syn.clone().detach().cpu()\n",
    "\n",
    "            # ensure the target directory exists\n",
    "            os.makedirs('./synthetic_data/', exist_ok=True)\n",
    "            torch.save({\n",
    "                \"x_syn\": best_x_syn,\n",
    "                \"y_syn\": best_y_syn,\n",
    "            }, os.path.join('./synthetic_data/', f'{init}_{ipc}.pth'))\n",
    "\n",
    "    # ---- Learning / updating the synthetic set for this iteration ----\n",
    "    # Create a fresh random network (same architecture you use for condensation)\n",
    "    net = get_net(input_dim=n_features, output_dim=1, device=device).to(device)\n",
    "    net.train()  # ensure train-mode if there are batchnorm/dropout layers\n",
    "\n",
    "    # We do not want gradients with respect to model parameters (only w.r.t. synthetic data),\n",
    "    # so freeze network parameters. Gradients must flow to synthetic tensors (x_syn).\n",
    "    for param in net.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Compute the distribution-matching (dm) loss across classes.\n",
    "    # Start as a zero-tensor on the device so backward() works correctly.\n",
    "    dm_loss = torch.tensor(0.0, device=device)\n",
    "\n",
    "    # For each class, compare the network outputs on real vs synthetic examples.\n",
    "    # We average/accumulate per-class squared difference of means in output space.\n",
    "    for c in range(num_classes):\n",
    "        # Determine how many real examples to sample for class c this iteration.\n",
    "        this_batch_real = min(len(get_data.indices_class[c]), args.batch_real)\n",
    "        # Sample from the real dataset for class c. Make sure it requires grad if you ever\n",
    "        # want gradients flowing to inputs (not typically necessary for pure DM loss).\n",
    "        batch_data_real = get_data(c, this_batch_real).to(device).requires_grad_(False)\n",
    "\n",
    "        # Select the corresponding slice of synthetic data for class c.\n",
    "        # x_syn is assumed to be arranged per-class in contiguous blocks:\n",
    "        #            x_syn[c * ipc : (c + 1) * ipc]\n",
    "        batch_data_syn = x_syn[c * ipc: (c + 1) * ipc].to(device)\n",
    "        batch_data_syn.requires_grad_(True)   # we want gradients w.r.t. the synthetic examples\n",
    "\n",
    "        # Forward through the frozen net.\n",
    "        # Detach the real outputs so they act as constants when comparing to synthetic outputs.\n",
    "        output_real = net(batch_data_real).detach()\n",
    "        output_syn = net(batch_data_syn)  # gradients will flow back to batch_data_syn\n",
    "\n",
    "        # Compare the mean network outputs per class (MSE between means).\n",
    "        # If output is batch x 1, torch.mean(..., dim=0) will produce shape (1,) so make sure shapes match.\n",
    "        mean_diff = torch.mean(output_real, dim=0) - torch.mean(output_syn, dim=0)\n",
    "        dm_loss += torch.sum(mean_diff ** 2)\n",
    "\n",
    "    # Update synthetic data using optimizer_x (assumed to optimize x_syn).\n",
    "    optimizer_x.zero_grad()\n",
    "    dm_loss.backward()\n",
    "    optimizer_x.step()\n",
    "\n",
    "    # Accumulate normalized loss for logging: divide by num_classes to report per-class average.\n",
    "    loss_sum += dm_loss.item() / float(num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# ---- Final evaluation of model trained on learned condensed dataset ----\n",
    "\n",
    "EPOCHS = 100\n",
    "device = device  # assume device is already set (e.g., \"cuda\" or \"cpu\")\n",
    "\n",
    "# Create model and optimizer (RNN here â€” keep consistent with training/eval nets).\n",
    "model = get_net(net_type='lstm', hidden_dim=32,input_dim=n_features, device=device).to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Path to saved condensed dataset\n",
    "syn_path = os.path.join('./synthetic_data/', f'{init}_{ipc}.pth')\n",
    "if not os.path.exists(syn_path):\n",
    "    raise FileNotFoundError(f\"Condensed dataset not found at {syn_path}\")\n",
    "\n",
    "# Load checkpoint (maps tensors to current device)\n",
    "checkpoint = torch.load(syn_path, map_location=device)\n",
    "best_x_syn = checkpoint[\"x_syn\"]\n",
    "best_y_syn = checkpoint[\"y_syn\"]\n",
    "\n",
    "# Move to device and ensure proper dtypes\n",
    "image_syn_eval = best_x_syn.to(device)\n",
    "label_syn_eval = best_y_syn.to(device)\n",
    "\n",
    "# Determine a sensible batch size for evaluation training\n",
    "syn_batch = int(min(256, len(image_syn_eval)))  # use length of loaded tensors\n",
    "\n",
    "# Build dataloader for synthetic dataset\n",
    "synthetic_dataset = torch.utils.data.TensorDataset(image_syn_eval, label_syn_eval)\n",
    "synthetic_loader = torch.utils.data.DataLoader(\n",
    "    synthetic_dataset, batch_size=syn_batch, shuffle=True, drop_last=False\n",
    ")\n",
    "\n",
    "# Logging / best validation tracker\n",
    "best_val_auc = -float(\"inf\")\n",
    "os.makedirs('./checkpoints', exist_ok=True)  # ensure directory exists for model saves\n",
    "\n",
    "# Optional: progress bar (commented out). Uncomment if tqdm is available.\n",
    "# from tqdm import trange, tqdm\n",
    "# epoch_iter = trange(EPOCHS, desc=\"Final Eval\")\n",
    "# for epoch in epoch_iter:\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # Train one epoch on the synthetic condensed dataset\n",
    "    for x_batch, y_batch in synthetic_loader:\n",
    "        # Ensure types and device; some nets expect float32 input.\n",
    "        x_batch = x_batch.to(torch.float32).to(device)\n",
    "        y_batch = y_batch.to(torch.float32).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(x_batch)\n",
    "\n",
    "        # If model returns (B,1), flatten to (B,) for many losses; leave as-is if already (B,)\n",
    "        if preds.dim() == 2 and preds.size(1) == 1:\n",
    "            preds = preds[:, 0]\n",
    "\n",
    "        loss = criterion(preds, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Average training loss per batch (safeguard if loader is empty)\n",
    "    avg_train_loss = running_loss / max(1, len(synthetic_loader))\n",
    "\n",
    "    # ---------- Validation ----------\n",
    "    # prediction_binary should evaluate model on val_loader and return (loss, auc, apr)\n",
    "    val_loss, val_auc, val_apr = prediction_binary(model, val_loader, criterion, device)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch+1}/{EPOCHS} â€” Train loss: {avg_train_loss:.4f} | \"\n",
    "        f\"Val loss: {val_loss:.4f} | Val AUC: {val_auc:.4f} | Val AUPRC: {val_apr:.4f}\"\n",
    "    )\n",
    "\n",
    "    # Save best model (save state_dict + metadata rather than whole model object)\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val_auc = val_auc\n",
    "        save_path = os.path.join('./checkpoints', 'dc_model_best.pth')\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_auc': val_auc,\n",
    "            'val_apr': val_apr,\n",
    "            'train_loss': avg_train_loss,\n",
    "        }, save_path)\n",
    "        print(f\"  -> New best Val AUC: {val_auc:.4f}. Saved checkpoint to {save_path}\")\n",
    "\n",
    "# After training, if you want to load the best model weights back into `model`, you can:\n",
    "# ckpt = torch.load('./checkpoints/dc_model_best.pth', map_location=device)\n",
    "# model.load_state_dict(ckpt['model_state_dict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict=torch.load('./checkpoints/dc_model_best.pth')\n",
    "model.load_state_dict(dict['model_state_dict'])\n",
    "test_loss, test_auc, test_apr = prediction_binary(model, test_loader, criterion, device)\n",
    "print(f\"Test loss: {test_loss:.4f} | Test AUC: {test_auc:.4f} | Test AUPRC: {test_apr:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
