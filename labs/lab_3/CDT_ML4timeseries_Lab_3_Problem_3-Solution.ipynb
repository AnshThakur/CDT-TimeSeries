{"cells":[{"cell_type":"markdown","metadata":{"id":"aROExh0q7Zdw"},"source":["# RNN VAE\n","<br>\n","\n","<font color='#2c3e50'>\n","    \n","In this exercise, we will extend our Seq2Seq AE to Variational Autoencoder. As discussed in lectures, we will only use an approximation of ELBO loss: `mean square error` for the first term and `KL divergence` between normal distribution and distribution of hidden vectors $\\mathbf{z}$.  \n","    \n","<br>\n","    \n","Apart ftom loss function, RNN VAE differs from Seq2Seq AE in only one way: In VAE, Encoder outputs a `distribution of hidden representation` (instead of a single vector as in Seq2Seq AE). One vector is randomly sampled from this distribution and is given as input to decoder. This process is referred to as `Reparameterisation Trick`. The decoder intialises its hidden state with this vector. The rest of functionality remains same.        \n","</font>\n","             \n","## 1. Task:\n","<font color='red'>\n","\n","<b>You need to partially implement reparameterisation trick:</b> \n","</font>\n","\n","<font color='#2c3e50'>\n","<ul>\n","<li>\n","\n","Modify `RNN_Autoencoder` class from the previous exercise.</li>\n","    \n","<li>\n","     \n","Complete `forward()` function of `RNN_Autoencoder` class. </li>\n","    \n","<li> \n","    \n","You need to map the hidden representation given by encoder to mean and standard deviation of a distribution using linear layers. You can add new layers or functions to `RNN_Autoencoder` class. </li> \n"," \n","\n","<li> \n","\n","The rest of the steps are already implemented. This mean and deviation are used for sampling a hidden state by `sample_standard_gaussian()`.</li> \n","\n","    \n","<li> \n","\n","Analyse the performance and compare against the previous models</li>\n","    \n","<li>\n","    \n","Analyse the mean and standard deviation of latent z distribution before and after training </li>\n","    \n","</ul>    \n","</font>\n","\n","\n","\n","## 2. Hint:\n","\n","<br>\n","<font color='#2c3e50'> \n","Implement a fully connected network (of multiple layers (your choice)) that takes a $D$ dimenional hidden vector as input and generates a $2\\times D$ dimenional vector. Consider first $D$ elements of this output vector as mean and remaining as standard deviation.\n","    \n","`Don't forget to use the Tanh activation between the hidden layers`. \n","\n","    \n"," You can analyse `sample_standard_gaussian()` in `utils.py`for more clues.     \n","</font>\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":26157,"status":"ok","timestamp":1636214341769,"user":{"displayName":"Anshul Thakur","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11719449395424920327"},"user_tz":0},"id":"2T5yJGhx7Zd8"},"outputs":[],"source":["import torch\n","from torch import nn\n","from torch.nn import functional as F\n","from tqdm import tqdm\n","import numpy as np\n","from utils import get_validation_score_VAE,split_last_dim,sample_standard_gaussian\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1636214341771,"user":{"displayName":"Anshul Thakur","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11719449395424920327"},"user_tz":0},"id":"Qs-qY03q7Zd_"},"outputs":[],"source":["class Encoder(nn.Module):\n","    def __init__(self, input_dim, hidden_dim,device):\n","        super().__init__()\n","        self.hidden_dim = hidden_dim\n","        self.rnn = nn.RNNCell(input_dim, hidden_dim)\n","        self.device=device\n","    \n","    def forward(self, x):\n","        hidden = self.init_hidden(x)\n","        time_steps=x.shape[1]  #shape of x is (batches,time_Steps,features)\n","        \n","        \n","        for i in range(0,time_steps):\n","            inputs=x[:,i] # (batch,features) shape\n","            hidden = self.rnn(inputs,hidden)        \n","        #### return hidden states obtained after final time-step\n","        return hidden\n","    \n","    def init_hidden(self, x):\n","        h0 = torch.zeros(x.size(0), self.hidden_dim)\n","        return h0.to(self.device)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1636214341772,"user":{"displayName":"Anshul Thakur","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11719449395424920327"},"user_tz":0},"id":"QjK97wOJ7ZeB"},"outputs":[],"source":["class Decoder(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, linear_latent_dim,device):\n","        super().__init__()\n","        self.hidden_dim = hidden_dim\n","        self.rnn = nn.RNNCell(input_dim, hidden_dim)\n","        self.linear_layers=nn.Sequential(nn.Linear(hidden_dim, linear_latent_dim),nn.Tanh(),nn.Linear(linear_latent_dim, input_dim),)\n","        self.device=device\n","        \n","    \n","    def forward(self, x,states):\n","        hidden = states\n","        time_steps=x.shape[1]  #shape of x is (batches,time_Steps,features)\n","        \n","        all_hidden=[]\n","        \n","        for i in range(0,time_steps):\n","            inputs=x[:,i] # (batch,features) shape\n","            hidden = self.rnn(inputs,hidden)\n","            all_hidden.append(hidden)\n","        #### return hidden states obtained after final time-step\n","        all_hidden=torch.stack(all_hidden) # (time_steps,batches,hidden_dim)\n","        \n","        all_hidden=all_hidden.transpose_(1,0)  #(batches,time_steps,hidden_dim)\n","        \n","        out=self.linear_layers(all_hidden)    # (batches,time_steps,hidden_dim)\n","        return out\n","    \n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1636214341773,"user":{"displayName":"Anshul Thakur","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11719449395424920327"},"user_tz":0},"id":"3eztFLrM7ZeD"},"outputs":[],"source":["class RNN_Autoencoder(nn.Module):\n","    \n","    def __init__(self, input_dim, hidden_dim, decoder_linear_dim,device):\n","        super().__init__()\n","        \n","        self.encoder=Encoder(input_dim,hidden_dim,device)  \n","        ###########################################\n","        # Write you code here: Define a layer or multiple layers for mapping z to mean and std \n","        \n","        self.z0_net=nn.Sequential(nn.Linear(hidden_dim, 256),nn.Tanh(),nn.Linear(256, hidden_dim * 2),)\n","        ###############################\n","        self.decoder=Decoder(input_dim,hidden_dim,decoder_linear_dim,device)\n","        self.fc = nn.Linear(hidden_dim, 1)\n","        self.activation = nn.Sigmoid()\n","        self.device=device\n","    \n","    \n","    def forward(self,x):\n","        states=self.encoder(x)\n","        \n","        #############################\n","        #write your code here\n","        \n","        z0_mean, z0_std = split_last_dim(self.z0_net(states))\n","        z0_std = z0_std.abs()\n","        ###################################\n","         \n","        z0_sample = sample_standard_gaussian(z0_mean, z0_std,self.device)\n","        \n","        recon=self.decoder(x,z0_sample)\n","        pred=self.fc(states) \n","        return recon, self.activation(pred),z0_mean,z0_std\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1636214341774,"user":{"displayName":"Anshul Thakur","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11719449395424920327"},"user_tz":0},"id":"hgHHFpHl7ZeF"},"outputs":[],"source":["    def kl_divergence(mu, std):\n","        kl_loss = -0.5 * (1 + std - torch.square(mu) - torch.exp(std))\n","        kl_loss=torch.mean(torch.sum(kl_loss,dim=1))\n","        return kl_loss"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":269,"status":"ok","timestamp":1636214342033,"user":{"displayName":"Anshul Thakur","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11719449395424920327"},"user_tz":0},"id":"pcwivINQ7ZeH"},"outputs":[],"source":["def trainer(model,training_set,validation_set,device,lr,store_name,epochs=10):\n","    ##### Recieve data and labels \n","    T,L=training_set \n","    Val_T,Val_L=validation_set\n","    \n","    ###### intialise optimiser and criterion\n","    \n","    optimizer_model = torch.optim.SGD(model.parameters(),lr,momentum=0.9, nesterov=True)\n","    \n","    criterion1 = nn.BCELoss().to(device)\n","    criterion2 = nn.MSELoss().to(device)\n","\n","\n","    best=0\n","    a=0.5\n","    b=0.5\n","    \n","    LOSS=[]                 # we are only interetsed in analysing BCE loss\n","    VAL_LOSS=[]\n","    \n","    \n","    for epoch in range(0,epochs):\n","        model.train()\n","        ELBO=0\n","        BC=0\n","        Total_loss=0\n","        for k in tqdm(range(0,len(T))):\n","            \n","            inputs=T[k]\n","            labels=L[k]\n","            \n","            inputs=torch.Tensor(inputs).to(device)\n","            labels=torch.Tensor(labels).type(torch.FloatTensor).to(device)\n","            \n","            recon,pred,mu,std=model(inputs)\n","            \n","            kl = kl_divergence(mu, std)\n","            mse=criterion2(recon,inputs)\n","            \n","            Elbo=(kl+mse) # Approximation of -ELBO\n","            \n","            loss1=criterion1(pred[:,0],labels)\n","        \n","            loss=a*loss1+b*Elbo\n","            \n","            optimizer_model.zero_grad()\n","            loss.backward()\n","            optimizer_model.step()\n","            \n","            ELBO=ELBO+Elbo\n","            BC=BC+loss1\n","            \n","            Total_loss=Total_loss+loss\n","             \n","        Val_ROC,val_loss=get_validation_score_VAE(model,Val_T,Val_L)\n","        LOSS.append((BC/len(T)).detach().cpu().numpy())\n","        VAL_LOSS.append(val_loss.detach().cpu().numpy())\n","        \n","        print(' Epoch: {:.1f} ElBO {:.4f} BCE_Loss {:.4f} Total_Loss {:.4f} Validation_AUC {:.4f}'.format(epoch,(ELBO/len(T)),(BC/len(T)),(Total_loss/len(T)), Val_ROC))\n","        if best<Val_ROC:\n","           torch.save(model, './'+store_name) \n","\n","    return torch.load('./'+store_name).to(device),LOSS, VAL_LOSS "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4588,"status":"ok","timestamp":1636214346618,"user":{"displayName":"Anshul Thakur","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11719449395424920327"},"user_tz":0},"id":"dHcj03kV7ZeJ","outputId":"8a31749a-f871-47a1-feec-73fd14abafb2"},"outputs":[],"source":["from get_data import get_training_data,get_validation_data\n","T,L=get_training_data(batch_size=32) # returns lists of training data and label batches\n","Val_T,Val_L=get_validation_data() # numpy arrays of validation data and labels\n","print(T[0].shape) # (batch_size,time_steps,n_features)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1636214346619,"user":{"displayName":"Anshul Thakur","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11719449395424920327"},"user_tz":0},"id":"VCz4K5Ki7ZeM"},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":10,"status":"ok","timestamp":1636214346620,"user":{"displayName":"Anshul Thakur","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11719449395424920327"},"user_tz":0},"id":"6NzrFJBL7ZeO","outputId":"a7b92c37-e01f-4e5b-ec68-039d120bf5c3"},"outputs":[],"source":["n_features=T[0].shape[2] # 59 dimensional vector at each time step\n","recurrent_units=128 # number of recurrent hidden units in encoder and decoder RNN Cells  \n","latent_linear_units=32 # units in linear layers in Decoder. This layer maps hidden states at each time-step to input space in reconstruction.\n","lr=0.001\n","\n","model=RNN_Autoencoder(n_features,recurrent_units,latent_linear_units,device)\n","print(model)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":103660,"status":"ok","timestamp":1636214450273,"user":{"displayName":"Anshul Thakur","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11719449395424920327"},"user_tz":0},"id":"H8AG3Enq7ZeP","outputId":"e825d237-44b0-4d4d-f03f-13f308229cb3"},"outputs":[],"source":["model=model.to(device)\n","model, training_loss, validation_loss=trainer(model,(T,L),(Val_T,Val_L),device,lr,store_name='RNN_VAE',epochs=10)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":388},"executionInfo":{"elapsed":569,"status":"ok","timestamp":1636214450816,"user":{"displayName":"Anshul Thakur","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11719449395424920327"},"user_tz":0},"id":"4eIr5ryy7ZeQ","outputId":"77ca15f6-7835-4c4b-8470-342afab52916"},"outputs":[],"source":["# Plot training and validation loss\n","import matplotlib.pyplot as plt\n","\n","fig, ax = plt.subplots(figsize=(5,5))\n","\n","lw = 2\n","\n","plt.tight_layout()\n","ax.plot(np.linspace(1, len(training_loss), num=len(training_loss)),training_loss, color='rebeccapurple',\n","         lw=2, linestyle='-', label='Training Loss')\n","\n","ax.plot(np.linspace(1, len(training_loss), num=len(training_loss)),validation_loss, color='r',\n","         lw=2, linestyle='-', label='Validation_loss')\n","\n","ax.set_xlabel('# Epochs',fontsize=14)\n","ax.set_ylabel('# Loss',fontsize=14)\n","ax.legend(loc=\"best\",fontsize=12)\n","\n","ax.tick_params(axis='x', labelsize=13)\n","ax.tick_params(axis='y', labelsize=13)\n","\n","\n","plt.grid(color='gray', linestyle='-', linewidth=0.1)\n","\n","\n","plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Problem 3 Solution.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.9.7 ('ml4timeseries')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"vscode":{"interpreter":{"hash":"c93591c313a95c8a89c667763bfd86bbb342a6e2dd3e91f10558630342cde4f4"}}},"nbformat":4,"nbformat_minor":0}
