{"cells":[{"cell_type":"markdown","metadata":{"id":"KAuubMeo4Njd"},"source":["# Sequence-to-sequence Autoencoder & Auxiliary Tasks\n","<br>\n","\n","<font color='#2c3e50'>\n","<ul>\n","    \n","<li>\n","    \n","This exercise will demonstrate how to implement a simple `Sequence-to Sequence (Seq2Seq)` autoencoder (AE).</li>\n","    \n","<li> \n","    \n","Apart from Seq2Seq AE, we will also see how to `regularise` the training of a model using an `auxiliary` task.</li>    \n","\n","    \n","<li> \n","\n","Similar to the previous problem, the `main task` is `time-series classification`. However, we will use Seq2Seq AE. As a result, an obvious choice for an `auxiliary task` is `time-series reconstruction`. </li>      \n","    \n","\n","<li> \n","    \n","Similar to previous problem, the code is `almost` complete, and you just need to implement a few functions.</li>\n","    \n","</ul>\n","    \n","</font>\n","\n","## 1. Tasks:\n","<br>\n","<font color='#2c3e50'>\n","<ul>\n","\n","<li>\n","    \n","Use the RNN unfolding implemented in previous tasks to write/complete ``forward()`` functions for Encoder and Decoder classes.</li>\n","\n","<li>\n","\n","Analyse the loss curves and see if you can `spot` regularisation behaviour. </li>  \n","\n","</font> "]},{"cell_type":"markdown","metadata":{"id":"SmoRDpht4Njh"},"source":["## 2. Hints:\n","<br>\n","\n","<font color='#2c3e50'>\n","\n","Major components of Se2Seq in this case are:    \n","<ul>\n","    \n","<li> <b>Encoder:</b> Its straightforward. Encoder just contains a RNNCell. Unroll it and obtain hidden state after last time-step. (Similar to last exercise)</li>\n","    \n","<li> <b>Classifier:</b> Takes the hidden state vector generated by encoder and maps in to 0/1 prediction     \n","\n","<li> <b>Decoder:</b> It consists of a RNNCell and a linear layer. (discussed below)</li>\n","      \n","</ul>    \n","</font>\n","\n","### 2.1 Decoder:\n","<br>\n","<font color='#2c3e50'>\n","\n","<ul>\n","<li> \n","        \n","<b>RNNCell:</b> Intialise the hidden state with the state vector generated by encoder. Here, you need to collect the hidden state vectors after each time-step. Process/transpose these hidden state vectors into shape of `(batch_size,n_steps,hidden_units)`</li>\n","    \n","\n","    \n","<li>\n","    \n","<b>Linear Layer:</b> It maps the hidden state vectors into input space i.e. reconstructs the time-series. `(Batch_size,n_steps,hidden_units)` to `(Batch_size,n_steps,input_dims)` </li>\n","       \n","</ul>\n"," \n","    \n","\n","<img src=\"./img/decoder.jpeg\" alt=\"Drawing\" style=\"width: 800px;\"/>    \n","\n","    \n","<b>Note:</b> Unlike discussion in lecture, we are here trying to reconstruct the time-series from step 1 to n (instead of n to 1). You can reverse the input time-series to do reconstruction in reverse order.     "]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":25957,"status":"ok","timestamp":1636213241111,"user":{"displayName":"Anshul Thakur","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11719449395424920327"},"user_tz":0},"id":"S4oT_SOV4Njj"},"outputs":[],"source":["import torch\n","from torch import nn\n","from torch.nn import functional as F\n","from tqdm import tqdm\n","import numpy as np\n","from utils import get_validation_score_AE\n","import warnings\n","import matplotlib.pyplot as plt\n","\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1636213241114,"user":{"displayName":"Anshul Thakur","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11719449395424920327"},"user_tz":0},"id":"Jliwv-BZ4Njm"},"outputs":[],"source":["class Encoder(nn.Module):\n","    def __init__(self, input_dim, hidden_dim,device):\n","        super().__init__()\n","        self.hidden_dim = hidden_dim\n","        self.rnn = nn.RNNCell(input_dim, hidden_dim)\n","        self.device=device\n","    \n","    def forward(self, x):\n","        hidden = self.init_hidden(x)\n","        time_steps=x.shape[1]                #shape of x is (batches,time_steps,features)\n","        \n","        ######################################\n","        # write your code here\n","        for i in range(0,time_steps):\n","            inputs=x[:,i]                    # (batch,features) shape\n","            hidden = self.rnn(inputs,hidden)        \n","                        \n","        #######################################\n","        return hidden                        # return hidden states obtained after final time-step\n","    \n","    def init_hidden(self, x):\n","        h0 = torch.zeros(x.size(0), self.hidden_dim)\n","        return h0.to(self.device)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1636213241115,"user":{"displayName":"Anshul Thakur","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11719449395424920327"},"user_tz":0},"id":"wT0zwKWy4Njn"},"outputs":[],"source":["class Decoder(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, linear_latent_dim,device):\n","        super().__init__()\n","        self.hidden_dim = hidden_dim\n","        self.rnn = nn.RNNCell(input_dim, hidden_dim)\n","        self.linear_layers=nn.Sequential(nn.Linear(hidden_dim, linear_latent_dim),nn.Sigmoid(),nn.Linear(linear_latent_dim, input_dim),)\n","        self.device=device\n","        \n","    \n","    def forward(self, x,states):\n","        hidden = states\n","        time_steps=x.shape[1]            #shape of x is (batches,time_Steps,features)\n","        \n","        all_hidden=[]\n","        ###################################\n","        # write your code here\n","        for i in range(0,time_steps):\n","            inputs=x[:,i]                # (batch,features) shape\n","            hidden = self.rnn(inputs,hidden)\n","            all_hidden.append(hidden)\n","\n","        all_hidden=torch.stack(all_hidden)     # (time_steps,batches,hidden_dim)\n","        \n","        all_hidden=all_hidden.transpose_(1,0)  #(batches,time_steps,hidden_dim)\n","        \n","        out=self.linear_layers(all_hidden)     # (batches,time_steps,hidden_dim)\n","        #######################################\n","        return out\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1636213241116,"user":{"displayName":"Anshul Thakur","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11719449395424920327"},"user_tz":0},"id":"wW9HFLOE4Njo"},"outputs":[],"source":["\n","class RNN_Autoencoder(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, decoder_linear_dim,device):\n","        super().__init__()\n","        self.encoder=Encoder(input_dim,hidden_dim,device)        \n","        self.decoder=Decoder(input_dim,hidden_dim,decoder_linear_dim,device)\n","        self.fc = nn.Linear(hidden_dim, 1)   # classification layer\n","        self.activation = nn.Sigmoid()\n","        self.device=device\n","    \n","    def forward(self,x):\n","        states=self.encoder(x)\n","        recon=self.decoder(x,states)\n","        pred=self.fc(states) \n","        return recon, self.activation(pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1636213241117,"user":{"displayName":"Anshul Thakur","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11719449395424920327"},"user_tz":0},"id":"BTJLkLZQ4Njp"},"outputs":[],"source":["def trainer(model,training_set,validation_set,device,lr,store_name,epochs=10):\n","    ##### Recieve data and labels \n","    T,L=training_set \n","    Val_T,Val_L=validation_set\n","    \n","    ###### intialise optimiser and criterion\n","    \n","    optimizer_model = torch.optim.SGD(model.parameters(),lr,momentum=0.9, nesterov=True)\n","    \n","    criterion1 = nn.BCELoss().to(device) # classification loss\n","    criterion2 = nn.MSELoss().to(device) # Reconstruction loss\n","\n","\n","    best=0\n","    \n","    a=0.5 # weightage of loss 1\n","    \n","    b=0.5 # weightage of loss 2\n","    \n","    LOSS=[]                 # we are only interetsed in analysing BCE loss\n","    VAL_LOSS=[]\n","    \n","    for epoch in range(0,epochs):\n","        model.train()\n","        Loss1=0\n","        Loss2=0\n","        Total_loss=0\n","        for k in range(0,len(T)):\n","            \n","            inputs=T[k]\n","            labels=L[k]\n","            \n","            inputs=torch.Tensor(inputs).to(device)\n","            labels=torch.Tensor(labels).type(torch.FloatTensor).to(device)\n","            \n","            recon,pred=model(inputs)\n","            \n","            loss1=criterion1(pred[:,0],labels)\n","            loss2=criterion2(recon,inputs)\n","            \n","            loss=a*loss1+b*loss2 # a+b=1 # combine both losses\n","            \n","            optimizer_model.zero_grad()\n","            loss.backward()\n","            optimizer_model.step()\n","            \n","            Loss1=Loss1+loss1\n","            Loss2=Loss2+loss2\n","            Total_loss=Total_loss+loss\n","        \n","        LOSS.append((Loss1/len(T)).detach().cpu().numpy())   \n","        Val_ROC, val_loss=get_validation_score_AE(model,Val_T,Val_L)\n","        VAL_LOSS.append(val_loss.detach().cpu().numpy())    \n","        \n","        print(' Epoch: {:.1f} MSE_loss {:.4f} BCE_Loss {:.4f} Total_Loss {:.4f} Validation_AUC {:.4f}'.format(epoch,(Loss2/len(T)),(Loss1/len(T)),(Total_loss/len(T)), Val_ROC))\n","        \n","        if best<Val_ROC:\n","           torch.save(model, './'+store_name) \n","\n","    return torch.load('./'+store_name).to(device),LOSS,VAL_LOSS     \n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5112,"status":"ok","timestamp":1636213246216,"user":{"displayName":"Anshul Thakur","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11719449395424920327"},"user_tz":0},"id":"qJe-Bq184Njq","outputId":"a4d1bf35-dda2-4266-cede-f3697455b134"},"outputs":[],"source":["### load data \n","from get_data import get_training_data,get_validation_data\n","T,L=get_training_data(batch_size=32)                #returns lists of training data and label batches\n","Val_T,Val_L=get_validation_data()                   # numpy arrays of validation data and labels\n","print(T[0].shape)                                   # (batch_size,time_steps,n_features)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1636213246217,"user":{"displayName":"Anshul Thakur","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11719449395424920327"},"user_tz":0},"id":"a9J1m7iS4Njs"},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":13,"status":"ok","timestamp":1636213246219,"user":{"displayName":"Anshul Thakur","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11719449395424920327"},"user_tz":0},"id":"CanqZ2Rw4Njt","outputId":"0f18867d-9dd9-40fc-ded8-8432cd3164bc"},"outputs":[],"source":["n_features=T[0].shape[2]      # 76 dimensional vector at each time step\n","recurrent_units=128          # number of recurrent hidden units in encoder and decoder RNN Cells  \n","latent_linear_units=32       # units in linear layers in Decoder. This layer maps hidden states at each time-step to input space in reconstruction.\n","lr=0.001\n","\n","# get model object\n","model=RNN_Autoencoder(n_features,recurrent_units,latent_linear_units,device)\n","print(model)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":88629,"status":"ok","timestamp":1636213334838,"user":{"displayName":"Anshul Thakur","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11719449395424920327"},"user_tz":0},"id":"-1gZlgYF4Nju","outputId":"a50f86be-09b7-4528-9c59-6c2c0e4cd86c"},"outputs":[],"source":["model=model.to(device)\n","model, training_loss, validation_loss=trainer(model,(T,L),(Val_T,Val_L),device,lr,store_name='lstm',epochs=10)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":391},"executionInfo":{"elapsed":558,"status":"ok","timestamp":1636213335371,"user":{"displayName":"Anshul Thakur","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11719449395424920327"},"user_tz":0},"id":"Zkl3g_Vn4Njv","outputId":"edd1e3d3-9032-40cd-baa2-53fc64d57897"},"outputs":[],"source":["# Plot training and validation loss\n","\n","fig, ax = plt.subplots(figsize=(5,5))\n","\n","lw = 2\n","\n","plt.tight_layout()\n","ax.plot(np.linspace(1, len(training_loss), num=len(training_loss)),training_loss, color='rebeccapurple',\n","         lw=2, linestyle='-', label='Training Loss')\n","\n","ax.plot(np.linspace(1, len(training_loss), num=len(training_loss)),validation_loss, color='r',\n","         lw=2, linestyle='-', label='Validation_loss')\n","\n","ax.set_xlabel('# Epochs',fontsize=14)\n","ax.set_ylabel('# Loss',fontsize=14)\n","ax.legend(loc=\"best\",fontsize=12)\n","\n","ax.tick_params(axis='x', labelsize=13)\n","ax.tick_params(axis='y', labelsize=13)\n","\n","\n","plt.grid(color='gray', linestyle='-', linewidth=0.1)\n","\n","\n","plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Problem 2 Solution.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.9.7 ('ml4timeseries')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"vscode":{"interpreter":{"hash":"c93591c313a95c8a89c667763bfd86bbb342a6e2dd3e91f10558630342cde4f4"}}},"nbformat":4,"nbformat_minor":0}
